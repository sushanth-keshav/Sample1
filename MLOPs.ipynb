{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d256fc",
   "metadata": {},
   "source": [
    "# Productionizing ML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62587699",
   "metadata": {},
   "source": [
    "## Requirements \n",
    "\n",
    "- Build model artifacts that contain all the information needed to preprocess the data and generate a result\n",
    "- Upon building model artifacts, we should be able to track the code that builds them, and the data they were trained and tested on\n",
    "- Need to keep track of how all three of these things, the models, their code, and their data, are related\n",
    "- Final stage is the deployment into production by triggering a CI/CD process\n",
    "- Major topics of interest is always about **reproducilibity, tracking and visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0caf2",
   "metadata": {},
   "source": [
    "## Data Pipelining and Versioning\n",
    "* https://startupstash.com/data-versioning-tools/\n",
    "\n",
    "* https://dagshub.com/blog/data-version-control-tools/\n",
    "\n",
    "Some interetsing open source tools are DVC, Pachyderm (Pachyderm is “the Docker of data”), Dolt, etc.,\n",
    "\n",
    "### How Can You Version Control?\n",
    "Git is fantastic, but maintaining all of your files synchronized in Git is a difficult effort for a data scientist. All of the superfluous space is taken up by the model checkpoints and data size. \n",
    "\n",
    "So, one option is to keep all of the data on a cloud server and all of the replicable code in Git, and then create the models on the fly. Although it appears to be a sensible decision, using different data sets in the same code can cause confusion and, if not adequately documented, can lead to data set mixing in the long term.\n",
    "\n",
    "In addition, if data changes/upgrades and all contributions are not adequately documented, the model may lose context.\n",
    "\n",
    "### Another intersting topic is : \"Data Governance\" \n",
    "\n",
    "DataLad is one good option... Currently not diving too much into this topic!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e252d51",
   "metadata": {},
   "source": [
    "## Run orchestration and workflow pipelines\n",
    "https://neptune.ai/blog/best-workflow-and-pipeline-orchestration-tools\n",
    "\n",
    "When your workflow has multiple steps (preprocessing, training, evaluation) that can be executed separately, you will benefit from a workflow pipeline and orchestration tool.\n",
    "\n",
    "Those tools will help us:\n",
    "\n",
    "- execute steps in the correct order\n",
    "- abstract away execution to any infrastructure\n",
    "- make sure that every step has all the inputs from other steps before it starts running\n",
    "- speed up the pipeline execution by saving/caching outputs from intermediate steps and running only those it has to\n",
    "- retry/rerun the steps that failed without crashing the entire pipeline\n",
    "- schedule/trigger pipeline execution based on time (every week) or events (every merge to the main branch)\n",
    "- visualize pipeline structure and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe4945",
   "metadata": {},
   "source": [
    "## Some other sources\n",
    "\n",
    "- https://github.com/EthicalML/awesome-production-machine-learning\n",
    "- https://github.com/visenger/awesome-mlops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70248ee9",
   "metadata": {},
   "source": [
    "## Our \"Mission\" \n",
    "\n",
    "Design a dynamic pipeline for:\n",
    "\n",
    "**Data Selection --> Feature Seelct/Storage --> Appropriate Model Selection and Training --> Model Ensemble --> Forecasting**\n",
    "\n",
    "- Even when different data shapes are present, the pipeline should automatically select a suitable model for example,  incase of limited time-series --> choose a regression model whereas using a complex model for large time series data, at the end check the lowest error, ensemble accordingly and provide a forecast. \n",
    "\n",
    "- When we have two different data sources, the pipeline needs to have an **Evaluation Module** based on teh similarities between datasets, whether to handle them separately or in a combined fashion\n",
    "\n",
    "### Current State\n",
    "We try using IF/ELSE statements to automate the data- Model combination and accordingly forecast\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2dc054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
